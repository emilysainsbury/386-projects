---
layout: post
title:  "Simple Linear Regression Tutorial (Emphasis on Simple)"
date:   2022-09-22
author: Emily Sainsbury
description: A Breif Overview on Linear Regression
image: /assets/images/Picture1.png
---


Are you new to linear regression, or has it been forever since you covered it in class? Understanding simple linear regression is the foundation for creating models, making predictions, and evidence-based decision making. So, let’s review it!

For this example, we’re going to be using a dataset called mpg, which compares a lot of different information about cars. We’ll be looking at the effect of displacement on highway gas mileage on a given car. Here’s what it looks like:

![Test Image](https://raw.githubusercontent.com/emilysainsbury/stat386-projects/main/assets/images/Picture2.png)

We can see there’s a bit of a downward trend in gas mileage when displacement increases. We can use regression techniques to learn if there is a relationship between the two variables, quantify the effect that displacement has on miles per gallon, and make predictions. 

# The Basic Structure of a Linear Model

𝑦𝑖=𝑁(𝛽o + 𝛽𝑖 𝑥𝑖, 𝜎^2 )

Where:

𝑦𝑖: the mpg of the ith car

𝑥𝑖: the displacement of the ith car

𝛽o: if the car’s displacement is 0, then the car will have this gas mileage (on average)

𝛽𝑖: if the car’s displacement increases by 1, the gas mileage will increase by this much on average.

𝜎^2: how far off the predicted average mpg is form the actual average mpg, on average

This formula resembles the basic formula of a line, y = mx+b. In the context of the mpg data, b is the gas mileage of a car that has 0 displacement (if that even exists), and m is the amount of change we see in highway gas mileage when you increase or decrease displacement by 1.  

# Fitting a Linear Model to Our Data

Using R to calculate the best intercept and slope for this data, we get something that looks like this: 


![Test Image](https://raw.githubusercontent.com/emilysainsbury/stat386-projects/main/assets/images/Picture3.png)


The formula for this line is y = -3.5x + 35.7. So, what does that mean? Since the slope is negative, we know there is an inverse relationship between these two variables. We can use this formula to make predictions. For example, if we’re looking at a car that has a displacement of 4.5, we can look at the line and see that on average that car will have a highway gas mileage of 20 Mpg. Or, if you want a car that will have a gas milage of at least 25 mpg, you would find that on average you should be looking at cars with a displacement of 3 or less. 

# How Do I Know If I Can Even Trust This?

Not all linear models are created equal. The relationship between two given variables is not always completely consistent. That said, there are ways to test how reliable our model is. Calculating figures such as bias, root predicted mean squared error, and r squared are great for giving insight on how far off our predictions are, and how good our model is at explaining the variation in the response variable. 

# A Couple Caveats

Not every dataset is appropriate for linear regression, so there are a few rules we need to remember. Linear Regression works when 4 conditions are being met: Linearity, Independence, Normality, and Equal Variance (To help you remember, it spells out line!). There are simple ways to test for these conditions in R and Python, and if you find that your dataset does not meet these conditions then linear regression will not provide accurate insights. There are ways to work around this, but that’s for another day. 

This is simply a quick overview of linear regression. There are so many other things that could be covered such as what to do when one (or both) variables are categorical, what to do when the “line” assumptions aren’t met, and much more. 



